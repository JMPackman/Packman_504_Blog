{
  "hash": "a5baf62487ba4fe1f0a0d276baa61733",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Confirmatory Factor Analysis\"\nauthor: \"James Packman\"\ndate: \"2025-05-01\"\ncategories: [news, code, analysis]\nimage: \"confirm copy.png\"\n---\n\n\n\nNow that you have a solid foundation for factor analysis, and have completed EFA, let's turn our attention to confirmatory factor analysis (CFA). You're workflow should consist of EFA, then CFA. CFA is the factor analysis you conduct when you have a hypothesis about what the underlying factor structure among variables in your data should look like.\n\nNote that you shouldn't conduct EFA and CFA on the same data set. That would be like betting on a baseball game you've already seen. Instead, you should watch some baseball games (your EFA), then, when you have a sense of the pattern, bet on the next one (note: this post does not constitute an endorsement of gambling).\n\nConsequently, we got a whole new data set for a whole new ball game. Note that scale responses range from 0-5, rather than 1-6 in this study (both are still 6-point Likert scales).\n\n# Exploratory Data Analysis\n\nLet's load our required packages and then our data set, which has the same variables from last time.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"papaja\")\nlibrary(GPArotation)\nlibrary(tidyr)\nlibrary(nFactors)\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(psych)\nlibrary(dplyr)\nlibrary(Rmisc)\nlibrary(coefficientalpha)\nlibrary(lavaan)\nlibrary(ggpubr)\nlibrary(mvnormtest)\nlibrary(QuantPsyc)\nlibrary(ltm)\nlibrary(easystats)\nlibrary(performance)\nlibrary(parameters)\nlibrary(InteractionPoweR)\nlibrary(magick)\nlibrary(plyr)\nlibrary(knitr)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Load in data set\nSASSCFAdata <- read.csv(\"SASSCFA.csv\")  \n\n#Subset columns to only include Scale of Antisemitic Stereotypes (SASS)\nSASSCFA <- data.frame(SASSCFAdata[,44:52])\n#Summary Statistics - Full Scale\n\ncronbach.alpha(SASSCFA, CI = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCronbach's alpha for the 'SASSCFA' data-set\n\nItems: 9\nSample units: 394\nalpha: 0.854\n\nBootstrap 95% CI based on 1000 samples\n 2.5% 97.5% \n0.826 0.875 \n```\n\n\n:::\n:::\n\n\n\nWe get a similar Cronbach's alpha as we did last time; we've got pretty good internal consistency for the full set of variables. Here's another summary table.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: (\\#tab:unnamed-chunk-3) Scale of Antisemitic Stereotypes Descriptive Statistics - CFA Study\n\n\nQuestions                                                            Mean   Median   SD   \n-------------------------------------------------------------------  -----  -------  -----\nJewish people are often very rude                                    1.20   1.00     1.10 \nJewish people tend to complain a lot                                 1.46   1.00     1.14 \nAll things considered, Jewish people are untrustworthy               0.94   1.00     1.03 \nJewish people can be sneaky                                          1.60   1.00     1.31 \nWhen they feel slighted, Jewish people will be vengeful              1.60   1.00     1.22 \nJewish people tend to influence the media                            2.19   2.00     1.38 \nJewish people tend to be good with money                             3.39   3.00     0.97 \nWhen it comes to education, Jewish people tend to be overachievers   2.87   3.00     1.10 \nOn the whole, Jewish people are loyal to Israel                      3.04   3.00     1.19 \n\n<div custom-style='table-note'>\n*Note.* Item scores are scored 0-5 ('strongly disagree' - strongly agree')\n</div>\n\n&nbsp;\n\n\n:::\n:::\n\n\n\n# Pre-CFA Test\n\nNext, we have to make sure our data are suitable for CFA.\n\n## Multivariate Normality Test\n\nFactor analysis assumes multivariate normality; that is, that the data are roughly normally distributed in multivariate space. We can also use the performance::check we did in EFA to conduct the KMO and Sphericity tests.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Mardia's Multivariate Normality Test\nmult.norm(SASSCFA)$mult.test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Beta-hat    kappa p-val\nSkewness  10.9399 718.3868     0\nKurtosis 120.9176  15.4589     0\n```\n\n\n:::\n\n```{.r .cell-code}\nperformance::check_factorstructure(SASSCFA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Is the data suitable for Factor Analysis?\n\n\n  - Sphericity: Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(36) = 1578.54, p < .001).\n  - KMO: The Kaiser, Meyer, Olkin (KMO) overall measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.89). The individual KMO scores are: Jewish.people.tend.to.complain.a.lot. (0.92), Jewish.people.are.often.very.rude. (0.89), All.things.considered..Jewish.people.are.untrustworthy. (0.89), Jewish.people.can.be.sneaky. (0.91), When.they.feel.slighted..Jewish.people.will.be.vengeful. (0.91), Jewish.people.tend.to.influence.the.media. (0.93), Jewish.people.tend.to.be.good.with.money. (0.75), When.it.comes.to.education..Jewish.people.tend.to.be.overachievers. (0.84), On.the.whole..Jewish.people.are.loyal.to.Israel. (0.77).\n```\n\n\n:::\n:::\n\n\n\nUnfortunately, because the test returned significant results, that means our data are not only skewed, but also leptokurtic. There is some evidence to suggest that this is rather common in socially sensitive research areas like stereotyping and prejudice. We'll do our best to account for these characteristics of the data going forward.\n\nBut the good news is, the other tests indicated that our data has adequate sampling and correlation for factor analysis. Onward!\n\n# Model Specification and Fit\n\nWe next specify which variables we think go into which factors. This is where our previous EFA is helpful; we can organize the variables into the factors onto which they loaded in EFA. We name the factors \"warmth\" and \"competence\" based on our prior understanding of the theory.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Two-factor (TF) model specification\nTF.model <- ' warmth =~ Jewish.people.are.often.very.rude. +\n                  Jewish.people.tend.to.complain.a.lot. +\n                  All.things.considered..Jewish.people.are.untrustworthy. +\n                    Jewish.people.can.be.sneaky. +\n                    When.they.feel.slighted..Jewish.people.will.be.vengeful. +\n                    Jewish.people.tend.to.influence.the.media. \n              competence =~  Jewish.people.tend.to.be.good.with.money. +\n         When.it.comes.to.education..Jewish.people.tend.to.be.overachievers. +\n         On.the.whole..Jewish.people.are.loyal.to.Israel.'\n```\n:::\n\n\n\nNext, we'll calculate how well this two-factor model fits our data. Because the data is skewed and leptokurtic, we'll use a maximum likelihood estimation with robust (Huber-White) standard errors.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfitTF <-cfa(TF.model, data = SASSCFA, estimator=\"MLR\") #Maximum likelihood estimator\nsummary(fitTF, fit.measures = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-19 ended normally after 31 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        19\n\n  Number of observations                           394\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                89.075      76.569\n  Degrees of freedom                                26          26\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.163\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              1598.143    1240.402\n  Degrees of freedom                                36          36\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.288\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.960       0.958\n  Tucker-Lewis Index (TLI)                       0.944       0.942\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.962\n  Robust Tucker-Lewis Index (TLI)                            0.948\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4779.357   -4779.357\n  Scaling correction factor                                  1.369\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -4734.819   -4734.819\n  Scaling correction factor                                  1.250\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                                9596.714    9596.714\n  Bayesian (BIC)                              9672.265    9672.265\n  Sample-size adjusted Bayesian (SABIC)       9611.978    9611.978\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.078       0.070\n  90 Percent confidence interval - lower         0.061       0.054\n  90 Percent confidence interval - upper         0.097       0.087\n  P-value H_0: RMSEA <= 0.050                    0.005       0.024\n  P-value H_0: RMSEA >= 0.080                    0.465       0.183\n                                                                  \n  Robust RMSEA                                               0.076\n  90 Percent confidence interval - lower                     0.056\n  90 Percent confidence interval - upper                     0.096\n  P-value H_0: Robust RMSEA <= 0.050                         0.016\n  P-value H_0: Robust RMSEA >= 0.080                         0.383\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.056       0.056\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  warmth =~                                           \n    Jwsh.ppl.r....    1.000                           \n    Jwsh.ppl......    1.002    0.065   15.422    0.000\n    All.th...J....    0.955    0.063   15.243    0.000\n    Jwsh.ppl.cn...    1.176    0.081   14.569    0.000\n    Whn.....J.....    1.137    0.080   14.202    0.000\n    Jwsh.ppl......    0.947    0.085   11.109    0.000\n  competence =~                                       \n    Jwsh.pp.......    1.000                           \n    W......J......    0.919    0.131    7.012    0.000\n    On....J.....I.    0.966    0.123    7.855    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  warmth ~~                                           \n    competence        0.260    0.048    5.391    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .Jwsh.ppl.r....    0.423    0.051    8.303    0.000\n   .Jwsh.ppl......    0.510    0.060    8.484    0.000\n   .All.th...J....    0.347    0.038    9.035    0.000\n   .Jwsh.ppl.cn...    0.632    0.092    6.906    0.000\n   .Whn.....J.....    0.479    0.056    8.607    0.000\n   .Jwsh.ppl......    1.199    0.095   12.630    0.000\n   .Jwsh.pp.......    0.461    0.081    5.718    0.000\n   .W......J......    0.794    0.090    8.857    0.000\n   .On....J.....I.    0.948    0.092   10.316    0.000\n    warmth            0.781    0.100    7.837    0.000\n    competence        0.486    0.101    4.814    0.000\n```\n\n\n:::\n:::\n\n\n\nOkay, this output gives us a lot. Note the covariance between the factors! But we can make our lives easier by computing the model fit indices we want:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#We use \"scaled\" to provide a scaling correction factor (i.e., the Yuan-Bentler correction, Mplus variant)\nfitTF.scaled<-c(\"chisq.scaled\", \"cfi.scaled\", \"tli.scaled\", \"rmsea.scaled\", \"srmr\", \"aic\", \"bic\")  \nTwo_Factor_Fit <- fitmeasures(fitTF, fitTF.scaled)\nTwo_Factor_Fit %>%\n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|             |            x|\n|:------------|------------:|\n|chisq.scaled | 7.656897e+01|\n|cfi.scaled   | 9.580132e-01|\n|tli.scaled   | 9.418645e-01|\n|rmsea.scaled | 7.025986e-02|\n|srmr         | 5.618755e-02|\n|aic          | 9.596714e+03|\n|bic          | 9.672265e+03|\n\n\n:::\n:::\n\n\n\nThis is much easier to interpret. But what are we comparing this two-factor model against? We also need to specify our one-factor \"baseline\" model. This is the model where all the variables are under the same factor (i.e., there are no underlying factors; everything goes together.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#One-factor (OF) model specification and fit\nOF.model <- ' all =~ Jewish.people.are.often.very.rude. +\n                  Jewish.people.tend.to.complain.a.lot. +\n                  All.things.considered..Jewish.people.are.untrustworthy. +\n                    Jewish.people.can.be.sneaky. +\n                    When.they.feel.slighted..Jewish.people.will.be.vengeful. +\n                    Jewish.people.tend.to.influence.the.media. + Jewish.people.tend.to.be.good.with.money. +\n         When.it.comes.to.education..Jewish.people.tend.to.be.overachievers. +\n         On.the.whole..Jewish.people.are.loyal.to.Israel. '\nfitOF <-cfa(OF.model, data = SASSCFA, estimator=\"MLR\")\nsummary(fitOF, fit.measures = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-19 ended normally after 23 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n  Number of observations                           394\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               207.086     175.462\n  Degrees of freedom                                27          27\n  P-value (Chi-square)                           0.000       0.000\n  Scaling correction factor                                  1.180\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              1598.143    1240.402\n  Degrees of freedom                                36          36\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.288\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.885       0.877\n  Tucker-Lewis Index (TLI)                       0.846       0.836\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.887\n  Robust Tucker-Lewis Index (TLI)                            0.849\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4838.362   -4838.362\n  Scaling correction factor                                  1.356\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)      -4734.819   -4734.819\n  Scaling correction factor                                  1.250\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                                9712.724    9712.724\n  Bayesian (BIC)                              9784.299    9784.299\n  Sample-size adjusted Bayesian (SABIC)       9727.185    9727.185\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.130       0.118\n  90 Percent confidence interval - lower         0.114       0.103\n  90 Percent confidence interval - upper         0.147       0.134\n  P-value H_0: RMSEA <= 0.050                    0.000       0.000\n  P-value H_0: RMSEA >= 0.080                    1.000       1.000\n                                                                  \n  Robust RMSEA                                               0.128\n  90 Percent confidence interval - lower                     0.111\n  90 Percent confidence interval - upper                     0.147\n  P-value H_0: Robust RMSEA <= 0.050                         0.000\n  P-value H_0: Robust RMSEA >= 0.080                         1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.092       0.092\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  all =~                                              \n    Jwsh.ppl.r....    1.000                           \n    Jwsh.ppl......    1.010    0.066   15.363    0.000\n    All.th...J....    0.955    0.063   15.224    0.000\n    Jwsh.ppl.cn...    1.186    0.081   14.635    0.000\n    Whn.....J.....    1.149    0.081   14.122    0.000\n    Jwsh.ppl......    0.968    0.088   11.054    0.000\n    Jwsh.pp.......    0.317    0.073    4.370    0.000\n    W......J......    0.419    0.083    5.072    0.000\n    On....J.....I.    0.349    0.088    3.957    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .Jwsh.ppl.r....    0.435    0.051    8.453    0.000\n   .Jwsh.ppl......    0.510    0.060    8.529    0.000\n   .All.th...J....    0.357    0.039    9.110    0.000\n   .Jwsh.ppl.cn...    0.631    0.091    6.973    0.000\n   .Whn.....J.....    0.473    0.055    8.605    0.000\n   .Jwsh.ppl......    1.180    0.094   12.549    0.000\n   .Jwsh.pp.......    0.870    0.079   10.954    0.000\n   .W......J......    1.069    0.076   13.992    0.000\n   .On....J.....I.    1.308    0.093   14.053    0.000\n    all               0.769    0.100    7.723    0.000\n```\n\n\n:::\n\n```{.r .cell-code}\nfitOF.scaled<-c(\"chisq.scaled\", \"cfi.scaled\", \"tli.scaled\", \"rmsea.scaled\", \"srmr\", \"aic\", \"bic\")  \nOne_Factor_Fit <- fitmeasures(fitOF, fitOF.scaled) \nOne_Factor_Fit %>%\n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|             |            x|\n|:------------|------------:|\n|chisq.scaled | 1.754618e+02|\n|cfi.scaled   | 8.767340e-01|\n|tli.scaled   | 8.356454e-01|\n|rmsea.scaled | 1.181347e-01|\n|srmr         | 9.241804e-02|\n|aic          | 9.712724e+03|\n|bic          | 9.784299e+03|\n\n\n:::\n:::\n\n\n\n## Model Comparison\n\nWe can now compare the fit indices we calculated for our two-factor and one-factor models. To make this easier, let's put them in a table. We'll also add in the \"ideal\" cutoff criteria from Hu & Bentler (1999):\n\n\n\n::: {.cell}\n::: {.cell-output-display}\nTable: (\\#tab:unnamed-chunk-9) Scale of Antisemitic Stereotypes Factor Fit Indices\n\n\nFit\\_Index       One Factor Model   Two Factor Model   Hu \\& Bentler (1999) Cutoff Criteria \n---------------  -----------------  -----------------  -------------------------------------\nChi-Sq. Scaled   175.46             76.57              -                                    \nCFI Scaled       0.88               0.96               0.95                                 \nTLI Scaled       0.84               0.94               0.95                                 \nRMSEA Scaled     0.12               0.07               0.06                                 \nSRMR             0.09               0.06               0.08                                 \nAIC              9,712.72           9,596.71           -                                    \nBIC              9,784.30           9,672.26           -                                    \n\n<div custom-style='table-note'>\n*Note.* Maximum Likelihood estimator with robust standard errors\n</div>\n\n&nbsp;\n\n\n:::\n:::\n\n\n\nBased on these criteria, the two-factor model seems to fit the data better. The two-factor model also does a pretty good job of fulfilling the Hu & Bentler (1999) criteria, especially for such our relatively small sample (N = 394).\n\nIf you're still not convinced, you can also run an ANOVA comparing the two models:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(fitOF, fitTF)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan->lavTestLRT():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n      Df    AIC    BIC   Chisq Chisq diff Df diff Pr(>Chisq)    \nfitTF 26 9596.7 9672.3  89.075                                  \nfitOF 27 9712.7 9784.3 207.086     72.864       1  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\nAccording to the output, the fit indices for our two-factor model are significantly different (i.e., better) than for our one-factor model.\n\n## Interpreting our Factors\n\nNow we return to the familiar process of unpacking and interpreting our factors. Let's get the factor loadings for our two-factor model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Factor Loadings for 2-Factor Model\nSASS_CFA_Loadings <- psych::fa(SASSCFA, nfactors = 2, rotate=\"oblimin\", fm=\"ml\") %>% model_parameters(sort = TRUE, threshold = \"max\")\n\nSASS_CFA_Loadings\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Rotated loadings from Factor Analysis (oblimin-rotation)\n\nVariable                                                            |  ML1\n--------------------------------------------------------------------------\nAll.things.considered..Jewish.people.are.untrustworthy.             | 0.87\nJewish.people.are.often.very.rude.                                  | 0.85\nWhen.they.feel.slighted..Jewish.people.will.be.vengeful.            | 0.78\nJewish.people.can.be.sneaky.                                        | 0.77\nJewish.people.tend.to.complain.a.lot.                               | 0.76\nJewish.people.tend.to.influence.the.media.                          | 0.47\nJewish.people.tend.to.be.good.with.money.                           |     \nWhen.it.comes.to.education..Jewish.people.tend.to.be.overachievers. |     \nOn.the.whole..Jewish.people.are.loyal.to.Israel.                    |     \n\nVariable                                                            |  ML2\n--------------------------------------------------------------------------\nAll.things.considered..Jewish.people.are.untrustworthy.             |     \nJewish.people.are.often.very.rude.                                  |     \nWhen.they.feel.slighted..Jewish.people.will.be.vengeful.            |     \nJewish.people.can.be.sneaky.                                        |     \nJewish.people.tend.to.complain.a.lot.                               |     \nJewish.people.tend.to.influence.the.media.                          |     \nJewish.people.tend.to.be.good.with.money.                           | 0.74\nWhen.it.comes.to.education..Jewish.people.tend.to.be.overachievers. | 0.55\nOn.the.whole..Jewish.people.are.loyal.to.Israel.                    | 0.55\n\nVariable                                                           \n-------------------------------------------------------------------\nAll.things.considered..Jewish.people.are.untrustworthy.            \nJewish.people.are.often.very.rude.                                 \nWhen.they.feel.slighted..Jewish.people.will.be.vengeful.           \nJewish.people.can.be.sneaky.                                       \nJewish.people.tend.to.complain.a.lot.                              \nJewish.people.tend.to.influence.the.media.                         \nJewish.people.tend.to.be.good.with.money.                          \nWhen.it.comes.to.education..Jewish.people.tend.to.be.overachievers.\nOn.the.whole..Jewish.people.are.loyal.to.Israel.                   \n\nComplexity | Uniqueness\n-----------------------\n      1.02 |       0.30\n      1.02 |       0.33\n      1.03 |       0.33\n      1.01 |       0.37\n      1.01 |       0.40\n      1.76 |       0.55\n      1.01 |       0.47\n      1.05 |       0.65\n      1.00 |       0.69\n\nThe 2 latent factors (oblimin rotation) accounted for 54.51% of the total variance of the original data (ML1 = 39.42%, ML2 = 15.09%).\n```\n\n\n:::\n:::\n\n\n\nAs you can see, our results are comparable to the loadings our EFA yielded. That gives us confidence that the factor structure of our data is consistent across samples! Once again, ML1 is our \"warmth\" dimension, while ML2 is our \"competence\" dimension.\n\nLet's calculate the internal consistency of each factor.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nWarmth <- SASSCFA %>%\n    dplyr::select(\"Jewish.people.are.often.very.rude.\",\n                  \"Jewish.people.tend.to.complain.a.lot.\",\n                  \"All.things.considered..Jewish.people.are.untrustworthy.\",\n                    \"Jewish.people.can.be.sneaky.\",\n                    \"When.they.feel.slighted..Jewish.people.will.be.vengeful.\",\n                    \"Jewish.people.tend.to.influence.the.media.\")\nCompetence <- SASSCFA %>%\n  dplyr::select(\"Jewish.people.tend.to.be.good.with.money.\",\n         \"When.it.comes.to.education..Jewish.people.tend.to.be.overachievers.\",\n         \"On.the.whole..Jewish.people.are.loyal.to.Israel.\")\nWarmthAlpha <- cronbach.alpha(Warmth, standardized = TRUE, CI = TRUE)\nCompAlpha <- cronbach.alpha(Competence, standardized = TRUE, CI = TRUE)\nWarmthAlpha\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nStandardized Cronbach's alpha for the 'Warmth' data-set\n\nItems: 6\nSample units: 394\nalpha: 0.897\n\nBootstrap 95% CI based on 1000 samples\n 2.5% 97.5% \n0.877 0.914 \n```\n\n\n:::\n\n```{.r .cell-code}\nCompAlpha\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nStandardized Cronbach's alpha for the 'Competence' data-set\n\nItems: 3\nSample units: 394\nalpha: 0.649\n\nBootstrap 95% CI based on 1000 samples\n 2.5% 97.5% \n0.571 0.712 \n```\n\n\n:::\n:::\n\n\n\nOnce again, we have really good internal consistency with our first factor, but a little shaky with our second factor. So, it might be that the first factor is pretty solid, and the other items represent loosely-grouped \"other stuff\" outside of that factor.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}